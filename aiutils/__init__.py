import tiktoken
from .json_manager import check_for_update
from openai import OpenAI
import datetime
import os
import mimetypes

def load_pricing_data():
    """
    Load the pricing data, checking if an update is needed.
    If the pricing data is outdated, prompt the user to update.
    """
    return check_for_update()

def pricecheck(response, comparison_model=None):
    """
    Calculate the cost of tokens generated by an OpenAI model based on the pricing data.

    Parameters:
    response: The response object from the OpenAI API.
    comparison_model: An optional model name for cost comparison.

    Returns:
    A string detailing the model used, tokens consumed, and the total cost.
    """
    pricing_data = load_pricing_data()

    model_name = response.model
    output_tokens = response.usage.completion_tokens
    input_tokens = response.usage.prompt_tokens

    # Determine the correct model for pricing
    if model_name in pricing_data['models']:
        model_pricing = pricing_data['models'][model_name]
    else:
        if model_name in pricing_data['mapping']:
            mapped_model = pricing_data['mapping'][model_name]
            model_pricing = pricing_data['models'][mapped_model]
        else:
            raise ValueError(f"Model {model_name} not found in pricing data and no mapping exists.")

    # Calculate costs for the selected model
    input_cost = model_pricing['standard']['input'] * (input_tokens / 1_000_000)
    output_cost = model_pricing['standard']['output'] * (output_tokens / 1_000_000)
    total_cost = input_cost + output_cost
    total_tokens = input_tokens + output_tokens

    # Base results string
    results = f"""
    Model used: {model_name}
    Tokens | In: {input_tokens} | Out: {output_tokens} | Total: {total_tokens}
    Cost | In: ${input_cost:.4f} | Out: ${output_cost:.4f}, Total: ${total_cost:.4f}
    """

    # Comparison with another model, if provided
    if comparison_model:
        if comparison_model in pricing_data['models']:
            comparison_pricing = pricing_data['models'][comparison_model]
        else:
            if comparison_model in pricing_data['mapping']:
                mapped_comparison_model = pricing_data['mapping'][comparison_model]
                comparison_pricing = pricing_data['models'][mapped_comparison_model]
            else:
                raise ValueError(f"Comparison model {comparison_model} not found in pricing data and no mapping exists.")

        # Calculate comparison costs
        comparison_input_cost = comparison_pricing['standard']['input'] * (input_tokens / 1_000_000)
        comparison_output_cost = comparison_pricing['standard']['output'] * (output_tokens / 1_000_000)
        comparison_total_cost = comparison_input_cost + comparison_output_cost
        cost_difference = total_cost - comparison_total_cost

        comparison = "cheaper" if cost_difference > 0 else "more expensive" if cost_difference < 0 else "the same price"

        # Add comparison information to the results string
        comparison_results = f"""
        {comparison_model} Comparison:
        Input: ${comparison_input_cost:.4f} | Out: ${comparison_output_cost:.4f}, Total: ${comparison_total_cost:.4f}
        Cost Difference: {comparison_model} would be ${abs(cost_difference):.4f} {comparison}
        """
        
        # Append comparison results to the main results string
        results += comparison_results

    return results

def tokencount_file(input_file, model="gpt-4o"):
    """
    Count the number of tokens in a text file using the specified OpenAI model.

    Parameters:
    input_file: The file path to a text file.
    model: The model name for which to count tokens (default is 'gpt-4o').

    Returns:
    The token count for the input file.
    """
    encoding = tiktoken.encoding_for_model(model)

    def read_file(file_path):
        with open(file_path, 'r', encoding='utf-8') as file:
            return file.read()

    content = read_file(input_file)
    token_count = len(encoding.encode(content))

    return token_count

def tokencount_text(text, model="gpt-4o"):
    """
    Count the number of tokens in a given text string using the specified OpenAI model.

    Parameters:
    text: The input text string.
    model: The model name for which to count tokens (default is 'gpt-4o').

    Returns:
    The token count for the input text.
    """
    encoding = tiktoken.encoding_for_model(model)
    token_count = len(encoding.encode(text))

    return token_count

def quick_q(prompt,model="gpt-4o-mini"):

    client = OpenAI()

    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt},
        ]
    )

    return response

def quickprint(prompt,model="gpt-4o-mini"):

    response = quick_q(prompt,model=model)

    # set timestamp in yymmddHHMM format
    timestamp = datetime.datetime.now().strftime("%y%m%d%H%M")

    response_text = response.choices[0].message.content
    print(response_text)

    # Check if 'qq' directory exists, if not create it
    try:
        os.mkdir("qq")
    except FileExistsError:
        pass

    with open(f"qq/qq_{timestamp}.txt", "w") as f:
        f.write(response_text)
    
    cost = pricecheck(response)
    print(cost)

def printsetup():
    # Create 'utils' directory if it doesn't exist
    try:
        os.mkdir("utils")
    except FileExistsError:
        pass
    # Create empty 'printer.py' file if it doesn't exist
    with open("utils/printer.py", "w") as f:
        pass
    # Add 'ignore_files and ignore_dirs lists
    with open("utils/printer.py", "a") as f:
        f.write("import os")
        f.write("\nfrom aiutils import print_directory_contents, print_directory_tree\n")
        f.write("\nignore_files = [\"printer.py\"]")
        f.write("\nignore_dirs = [\"__pycache__\", \"venv\", \"node_modules\", \".git\"]")
        f.write("\nignore_extensions = [\".pyc\"]")
        f.write("\n")
        f.write("\nprint_directory_contents(\".\", ignore_dirs, ignore_files, ignore_extensions)")
        f.write("\n")
        f.write("\nprint_directory_tree(\".\", ignore_dirs)")
    

# Function to print the directory contents while ignoring certain directories, files, extensions, and non-readable files
# Function to check if a file is binary or not
def is_binary_file(file_path):
    mime_type, _ = mimetypes.guess_type(file_path)
    if mime_type is None:
        return True  # If we can't guess the type, assume it's binary
    return not mime_type.startswith('text')

# Function to print the directory contents while ignoring certain directories, files, extensions, and binary/non-readable files
def print_directory_contents(directory, ignore_dirs, ignore_files, ignore_extensions):
    with open('summary.md', 'w') as f:
        # Walk through the directory
        for root, dirs, files in os.walk(directory):
            # Modify dirs in-place to exclude ignored directories globally
            dirs[:] = [d for d in dirs if d not in ignore_dirs]

            # Loop through each file in the current directory
            for name in files:
                # Skip files in ignore_files list or those with ignored extensions
                if name in ignore_files or any(name.endswith(ext) for ext in ignore_extensions):
                    continue

                # Get the full file path
                file_path = os.path.join(root, name)

                # Skip binary files and non-readable files
                if is_binary_file(file_path) or not os.access(file_path, os.R_OK):
                    continue

                # Write the file name and its contents to summary.md
                f.write(f'# {file_path}\n\n```')
                with open(file_path, 'r') as file:
                    f.write(file.read())
                f.write('\n```\n')

def generate_directory_tree(directory, ignore_dirs, prefix="", is_last=True):
    tree = []
    
    # Walk through the directory
    for root, dirs, files in os.walk(directory):
        # Sort dirs and files for consistent output
        dirs[:] = sorted(dirs)
        file_count = len(files)
        dir_count = len(dirs)

        # Loop through each directory in the current level
        for i, d in enumerate(dirs):
            dir_path = os.path.join(root, d)
            is_last_dir = (i == dir_count - 1) and (file_count == 0)

            # Check if the directory is in the ignore list
            if d in ignore_dirs:
                # Include the directory in the tree but omit its contents
                tree.append(f'{prefix}{"└── " if is_last_dir else "├── "}{d}')
                tree.append(f'{prefix}    ├── //contents omitted//')
            else:
                # Include the directory and continue traversing
                tree.append(f'{prefix}{"└── " if is_last_dir else "├── "}{d}/')
                # Recurse into the directory
                tree += generate_directory_tree(os.path.join(root, d), ignore_dirs, prefix + ("    " if is_last_dir else "│   "), is_last_dir)

        # Loop through each file in the current directory
        sorted_files = sorted(files)
        for j, name in enumerate(sorted_files):
            is_last_file = (j == file_count - 1)
            tree.append(f'{prefix}{"└── " if is_last_file else "├── "}{name}')
        
        break  # Stop walking deeper into the directory (handle each directory individually in recursion)
    
    return tree

# Function to print the directory tree in standard format
def print_directory_tree(directory, ignore_dirs):
    tree = generate_directory_tree(directory, ignore_dirs)
    with open('tree.md', 'w') as f:
        f.write(f"{directory}/\n")
        f.write("\n".join(tree))
        f.write("\n")